{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1hnoa-SAkGCeSENfgMuwBJuNXXRhOh0P2",
      "authorship_tag": "ABX9TyNuBQFeZEHUhk8zahwq7nHx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bigboyfreezy/sign-language-detection/blob/main/SignLanguageDetector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SIGN LANGUAGE DETECTION WITH KERAS\n",
        "**Detecting Sign Language Letters in Real Time Using MediaPipe and Keras**\n"
      ],
      "metadata": {
        "id": "KCAbo7rxBN5F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA PREPARATION FOR TRAINING**\n",
        "1. **Matplotlib** - is a comprehensive library for creating static, animated, and interactive visualizations in Python.\n",
        "2. **Keras** - a high-level neural networks API running on top of TensorFlow.\n",
        "3. Sequential class  - from Keras, which is a linear stack of layers for building neural networks layer by layer\n"
      ],
      "metadata": {
        "id": "0oEruHfECA9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "#Imports various layers from Keras that are commonly used in convolutional neural networks (CNNs) for image classification tasks.\n",
        "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
        "#helps generate augmented images by applying various transformations to the input data during training.\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# function from scikit-learn, which is used to split the dataset into training and testing sets.\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Imports functions for generating a classification report and confusion matrix, which are useful for evaluating the performance of a classification model.\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "# callback from Keras, which dynamically adjusts the learning rate during training based on a specified condition, typically used to improve training performance.\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "KSMN4dO8BPrG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pre Processing Key Points**\n",
        "1. Normalization - In digital images, pixel values are typically represented as integers in the range [0, 255], where 0 corresponds to black and 255 corresponds to white. Normalizing by dividing by 255 scales these values to be in the range [0, 1]. This is a common preprocessing step for image data when working with neural networks. Normalization helps in stabilizing and accelerating the training process, making it easier for the optimization algorithm to converge.\n",
        "\n",
        "2. In deep learning models, especially convolutional neural networks (CNNs), the input data is often required to have a specific shape. The common shape for image data is a 4D tensor with dimensions (number of samples, height, width, channels).\n",
        "\n",
        "- The parameter -1 in the reshape operation is used to infer the number of samples automatically. It is a placeholder for the size of the first dimension, and the actual size is calculated based on the size of the remaining dimensions\n",
        "- 28, 28 represents the height and width of the images, assuming they are 28x28 pixels.\n",
        "- 1 is the number of channels. In this case, the images are assumed to be grayscale, so there is only one channel. For color images with RGB channels, this value would be 3."
      ],
      "metadata": {
        "id": "P8elWgDpL7q0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt:\n",
        "\n",
        "# Read the training and testing dataset from  CSV file\n",
        "train= pd.read_csv(\"/content/drive/MyDrive/sign_mnist_train/sign_mnist_train.csv\")\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/sign_mnist_test/sign_mnist_test.csv\")\n",
        "\n",
        "#  Extracts the labels (target variable) from the training and testing dataset and assigns them to the variable x_train and y_train.\n",
        "y_train = train['label']\n",
        "y_test = test['label']\n",
        "# Removes the 'label' column from both the training and testing DataFrames\n",
        "del train['label']\n",
        "del test['label']\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "label_binarizer = LabelBinarizer()\n",
        "y_train = label_binarizer.fit_transform(y_train)\n",
        "y_test = label_binarizer.fit_transform(y_test)\n",
        "\n",
        "x_train = train.values\n",
        "x_test = test.values\n",
        "\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "\n",
        "x_train = x_train.reshape(-1,28,28,1)\n",
        "x_test = x_test.reshape(-1,28,28,1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WVmG54jmHGjH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BreakDown Of ImageDatagenerator**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "ImageDataGenerator for data augmentation and defining a learning rate reduction callback. Let's break it down:\n",
        "\n",
        "- datagen = ImageDataGenerator(...): Creates an instance of ImageDataGenerator with various configuration options for data augmentation. This generator will be used to generate augmented images during training.\n",
        "\n",
        "- featurewise_center, samplewise_center, featurewise_std_normalization, and samplewise_std_normalization: These options control whether to center the mean and normalize the standard deviation of the input data. In this case, they are set to False.\n",
        "\n",
        "- zca_whitening: ZCA whitening is a form of data preprocessing that can enhance the effectiveness of the model by decorrelating the features. Here, it is set to False.\n",
        "\n",
        "- rotation_range: Randomly rotates images in the range specified (degrees, 0 to 180). It is set to 10 degrees.\n",
        "\n",
        "- zoom_range: Randomly zooms into the image. It is set to 0.1, meaning a maximum zoom of 10%.\n",
        "\n",
        "- width_shift_range and height_shift_range: Randomly shifts images horizontally and vertically by a fraction of the total width and height, respectively. Both are set to 0.1, allowing for a maximum shift of 10%.\n",
        "\n",
        "- horizontal_flip and vertical_flip: Randomly flip images horizontally and vertically. Both are set to False, meaning no flipping is applied.\n",
        "\n",
        "- datagen.fit(x_train): Fits the ImageDataGenerator on the training data (x_train). This calculates the necessary statistics (e.g., mean and standard deviation) needed for data augmentation based on the provided configuration.\n",
        "\n",
        "**learning_rate_reduction** = ReduceLROnPlateau(...): Creates an instance of ReduceLROnPlateau callback.\n",
        "\n",
        "- monitor='val_accuracy': Monitors the validation accuracy during training.\n",
        "\n",
        "- patience=2: Number of epochs with no improvement after which learning rate will be reduced.\n",
        "\n",
        "- verbose=1: Prints a message when the learning rate is reduced.\n",
        "\n",
        "- factor=0.5: Factor by which the learning rate will be reduced. In this case, it is reduced by half.\n",
        "\n",
        "- min_lr=0.00001: Lower bound on the learning rate."
      ],
      "metadata": {
        "id": "zOt1_7TNOSqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=False,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "datagen.fit(x_train)\n",
        "\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.5, min_lr=0.00001)"
      ],
      "metadata": {
        "id": "rHjfWUckOTAd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Layer Breakdown**\n",
        "Let's break down each layer:\n",
        "\n",
        "- model = Sequential(): Initializes a sequential model.\n",
        "\n",
        "Convolutional Layer 1:\n",
        "- 75 filters with a kernel size of (3,3).\n",
        "- strides=1: The step size of the convolution operation.\n",
        "- padding='same': Pads the input such that the output has the same height and width.\n",
        "- activation='relu': Applies the Rectified Linear Unit (ReLU) activation function.\n",
        "- input_shape=(28,28,1): Input shape of each image (height, width, channels), assuming grayscale images.\n",
        "\n",
        "Batch Normalization:\n",
        "- Normalizes the activations of the previous layer.\n",
        "\n",
        "MaxPooling Layer 1:\n",
        "\n",
        "- Performs max pooling with a pool size of (2,2).\n",
        "- strides=2: The step size of the pooling operation.\n",
        "- padding='same': Pads the input such that the output has the same height and width.\n",
        "\n",
        "Flatten Layer:\n",
        "- Flattens the input to a one-dimensional array.\n",
        "\n",
        "Fully Connected (Dense) Layer:\n",
        "- Fully connected layer with 512 units and ReLU activation.\n",
        "\n",
        "Dropout Layer:\n",
        "- Dropout(0.3): Applies dropout with a dropout rate of 0.3 to prevent overfitting.\n",
        "\n",
        "Output Layer:\n",
        "- Fully connected layer with 24 units (assuming 24 classes) and softmax activation for multi-class classification."
      ],
      "metadata": {
        "id": "F_sly_-ZPVLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(75 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
        "model.add(Conv2D(50 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
        "model.add(Conv2D(25 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units = 512 , activation = 'relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(units = 24 , activation = 'softmax'))"
      ],
      "metadata": {
        "id": "AHTq3Hh6PS0b"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. First We install the TensorFlow library, which is commonly used for machine learning and deep learning tasks.\n",
        "2. OpenCV library - Used in image processing and performing computer vision tasks. It is an open-source library that can be used to perform tasks like face detection, objection tracking, landmark detection, and much more\n",
        "3. Mediapipe library, a library by Google that simplifies the development of applications for detecting and tracking various keypoints on the human body.\n",
        "4.  Python os module, which provides a way of using operating system-dependent functionality, like reading or writing to the file system.\n",
        "5.  NumPy library, which provides support for large, multi-dimensional arrays and matrices, along with mathematical functions.\n",
        "6.  Pandas library, a powerful data manipulation and analysis library."
      ],
      "metadata": {
        "id": "dRhQG2_u89y_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8Y4fwZn8EUF"
      },
      "outputs": [],
      "source": [
        "! pip install tensorflow\n",
        "! pip install opencv-python\n",
        "! pip install mediapipe --user\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "\n",
        "from keras.models import load_model #function from the Keras library, which is used for loading pre-trained machine learning models\n",
        "import numpy as np\n",
        "import time #  allows you to measure and control the time taken by various operations.\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eKsulvK3ANPg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ak1Z7yG9AONW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}